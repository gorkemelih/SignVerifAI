{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üñäÔ∏è SignVerifAI - Advanced Training (v2.0)\n",
                "\n",
                "**New Features:**\n",
                "- üßä Freeze/Unfreeze: ƒ∞lk 3 epoch backbone dondur\n",
                "- ‚ö° OneCycleLR: max_lr=1e-3, min_lr=1e-6\n",
                "- üéØ Hard Negative Mining\n",
                "- üîÑ Mixed Precision (AMP)\n",
                "- üìä Threshold Tuning: EER / Max Accuracy / Max F1\n",
                "- üìà Log every 5 epochs (spam yok)\n",
                "\n",
                "**Runtime:** A100 GPU recommended\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ GPU Check & Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GPU kontrol√º\n",
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Clone & Install"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GitHub'dan klonla (en son kod)\n",
                "!rm -rf SignVerifAI\n",
                "!git clone https://github.com/gorkemelih/SignVerifAI.git\n",
                "%cd SignVerifAI\n",
                "\n",
                "# Baƒüƒ±mlƒ±lƒ±klarƒ± kur\n",
                "!pip install -e . -q\n",
                "print(\"‚úÖ Kurulum tamamlandƒ±!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Mount Google Drive & Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drive'dan verileri y√ºkle\n",
                "import os\n",
                "\n",
                "DRIVE_DATA_PATH = \"/content/drive/MyDrive/SignVerifAI/data_processed.zip\"\n",
                "\n",
                "if os.path.exists(DRIVE_DATA_PATH):\n",
                "    !unzip -q -o {DRIVE_DATA_PATH} -d .\n",
                "    print(\"‚úÖ Veriler y√ºklendi!\")\n",
                "else:\n",
                "    print(f\"‚ùå Dosya bulunamadƒ±: {DRIVE_DATA_PATH}\")\n",
                "    print(\"üëâ L√ºtfen Drive'a data_processed.zip y√ºkleyin.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Prepare Data Splits & Pairs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Metadata kontrol√º\n",
                "import pandas as pd\n",
                "\n",
                "metadata = pd.read_csv('data_processed/metadata.csv')\n",
                "print(f\"Toplam g√∂r√ºnt√º: {len(metadata)}\")\n",
                "print(f\"Ki≈üi sayƒ±sƒ±: {metadata['person_id'].nunique()}\")\n",
                "print(f\"\\nEtiket daƒüƒ±lƒ±mƒ±:\")\n",
                "print(metadata['label'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split olu≈ütur\n",
                "!signverify split\n",
                "\n",
                "# Pair'leri olu≈ütur (50k train, 10k val)\n",
                "!signverify pairs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Train Model üöÄ\n",
                "\n",
                "**Advanced Features:**\n",
                "- Freeze backbone: 3 epochs ‚Üí sonra unfreeze\n",
                "- OneCycleLR scheduler\n",
                "- Hard negative mining\n",
                "- Mixed precision (AMP)\n",
                "- Log every 5 epochs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Eƒüitim parametreleri\n",
                "EPOCHS = 30\n",
                "BATCH_SIZE = 128\n",
                "FREEZE_EPOCHS = 3\n",
                "SCHEDULER = \"onecycle\"\n",
                "LOG_EVERY = 5\n",
                "\n",
                "# Eƒüitimi ba≈ülat\n",
                "!signverify train \\\n",
                "    --device cuda \\\n",
                "    --epochs {EPOCHS} \\\n",
                "    --batch-size {BATCH_SIZE} \\\n",
                "    --freeze-epochs {FREEZE_EPOCHS} \\\n",
                "    --scheduler {SCHEDULER} \\\n",
                "    --log-every {LOG_EVERY}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Evaluate Model with Threshold Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test seti √ºzerinde deƒüerlendirme (threshold kar≈üƒ±la≈ütƒ±rmasƒ±)\n",
                "!signverify eval --device cuda --threshold-mode all"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sonu√ßlarƒ± g√∂r√ºnt√ºle\n",
                "from IPython.display import Image, display, Markdown\n",
                "\n",
                "print(\"üìä ROC Curve:\")\n",
                "display(Image('outputs/reports/roc_curve.png'))\n",
                "\n",
                "print(\"\\nüìä Score Distribution:\")\n",
                "display(Image('outputs/reports/score_distribution.png'))\n",
                "\n",
                "print(\"\\nüìä Confusion Matrix (Max Accuracy):\")\n",
                "display(Image('outputs/reports/confusion_matrix.png'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluation report\n",
                "with open('outputs/reports/eval_report.md', 'r') as f:\n",
                "    display(Markdown(f.read()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training history grafiƒüi\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "history = pd.read_csv('outputs/reports/train_history.csv')\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
                "\n",
                "axes[0,0].plot(history['epoch'], history['train_loss'], label='Train')\n",
                "axes[0,0].plot(history['epoch'], history['val_loss'], label='Val')\n",
                "axes[0,0].set_title('Loss')\n",
                "axes[0,0].legend()\n",
                "\n",
                "axes[0,1].plot(history['epoch'], history['auc'])\n",
                "axes[0,1].set_title('AUC')\n",
                "\n",
                "axes[1,0].plot(history['epoch'], history['eer'])\n",
                "axes[1,0].set_title('EER')\n",
                "\n",
                "axes[1,1].plot(history['epoch'], history['lr'])\n",
                "axes[1,1].set_title('Learning Rate')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Save Model to Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "import glob\n",
                "\n",
                "# En son run klas√∂r√ºn√º bul\n",
                "runs = sorted(glob.glob('outputs/models/run_*'))\n",
                "if runs:\n",
                "    latest_run = runs[-1]\n",
                "    dest = \"/content/drive/MyDrive/SignVerifAI/trained_models/\"\n",
                "    os.makedirs(dest, exist_ok=True)\n",
                "    \n",
                "    # Model dosyasƒ±nƒ± kopyala\n",
                "    shutil.copy(f\"{latest_run}/checkpoint_best.pt\", dest)\n",
                "    shutil.copy(f\"{latest_run}/config.json\", dest)\n",
                "    shutil.copy(f\"{latest_run}/train_history.csv\", dest)\n",
                "    \n",
                "    # Reports'u da kopyala\n",
                "    reports_dest = \"/content/drive/MyDrive/SignVerifAI/reports/\"\n",
                "    os.makedirs(reports_dest, exist_ok=True)\n",
                "    for f in glob.glob('outputs/reports/*'):\n",
                "        shutil.copy(f, reports_dest)\n",
                "    \n",
                "    print(f\"‚úÖ Model kaydedildi: {dest}\")\n",
                "    print(f\"‚úÖ Raporlar kaydedildi: {reports_dest}\")\n",
                "else:\n",
                "    print(\"‚ùå Eƒüitilmi≈ü model bulunamadƒ±.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìã Training Summary v2.0\n",
                "\n",
                "| Setting | Value |\n",
                "|---------|-------|\n",
                "| Epochs | 30 |\n",
                "| Batch Size | 128 |\n",
                "| Freeze Epochs | 3 |\n",
                "| Scheduler | OneCycleLR |\n",
                "| Max LR | 1e-3 |\n",
                "| Min LR | 1e-6 |\n",
                "| Hard Mining | ‚úì |\n",
                "| AMP | ‚úì |\n",
                "| Threshold Tuning | EER, Max Acc, Max F1 |"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "A100",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}